{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "This script shows how to predict stock prices using a basic RNN\n",
    "'''\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import os\n",
    "\n",
    "tf.set_random_seed(777) # reproducibility\n",
    "\n",
    "if \"DISPLAY\" not in os.environ:\n",
    "    # remove Travis CI Error\n",
    "    matplotlib.use('Agg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def MinMaxScaler(data):\n",
    "    ''' Min Max Normalization\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : numpy.ndarray\n",
    "        input data to be normalized\n",
    "        shape: [Batch size, dimension]\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    data : numpy.ndarry\n",
    "        normalized data\n",
    "        shape: [Batch size, dimension]\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] http://sebastianraschka.com/Articles/2014_about_feature_scaling.html\n",
    "\n",
    "    '''\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    # noise term prevents the zero division\n",
    "    return numerator / (denominator + 1e-7)\n",
    "\n",
    "\n",
    "# train Parameters\n",
    "seq_length = 7\n",
    "data_dim = 5\n",
    "hidden_dim = 10\n",
    "output_dim = 5\n",
    "learning_rate = 0.01\n",
    "iterations = 500\n",
    "\n",
    "# Open, High, Low, Volume, Close\n",
    "xy = np.loadtxt('./data/inputs.csv', delimiter=',')\n",
    "xy = xy[::-1] # reverse order (chronically ordered)\n",
    "xy = MinMaxScaler(xy)\n",
    "x = xy\n",
    "y = xy[:, [-1]] # Close as label\n",
    "\n",
    "# build a dataset\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, len(y) - seq_length):\n",
    "    _x = x[i:i + seq_length]\n",
    "    _y = y[i + seq_length] # Next close price\n",
    "    #print(_x, \"->\", _y)\n",
    "    dataX.append(_x)\n",
    "    dataY.append(_y)\n",
    "\n",
    "# train/test split\n",
    "train_size = int(len(dataY) * 0.7)\n",
    "test_size = len(dataY) - train_size\n",
    "trainX, testX = np.array(dataX[0:train_size]), np.array(\n",
    "    dataX[train_size:len(dataX)])\n",
    "trainY, testY = np.array(dataY[0:train_size]), np.array(\n",
    "    dataY[train_size:len(dataY)])\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, seq_length, data_dim])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "# build a LSTM network\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(\n",
    "    num_units=hidden_dim, state_is_tuple=True, activation=tf.tanh)\n",
    "outputs, _states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "Y_pred = tf.contrib.layers.fully_connected(\n",
    "    outputs[:, -1], output_dim, activation_fn=None) # We use the last cell's output\n",
    "\n",
    "# cost/loss\n",
    "loss = tf.reduce_sum(tf.square(Y_pred - Y)) # sum of the squares\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# RMSE\n",
    "targets = tf.placeholder(tf.float32, [None, 1])\n",
    "predictions = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square(targets - predictions)))\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training step\n",
    "    for i in range(iterations):\n",
    "        _, step_loss = sess.run([train, loss], feed_dict={\n",
    "                                X: trainX, Y: trainY})\n",
    "        print(\"[step: {}] loss: {}\".format(i, step_loss))\n",
    "\n",
    "    # Test step\n",
    "    test_predict = sess.run(Y_pred, feed_dict={X: testX})\n",
    "    \n",
    "\n",
    "    # Successful Rate\n",
    "    sum_score = 0.0;\n",
    "\n",
    "    for i in range(0, len(test_predict)-1):\n",
    "        if (test_predict[i,-1] < testY[i+1,-1]) == (test_predict[i,-1] < test_predict[i+1,-1]):\n",
    "            sum_score = sum_score + 1\n",
    "\n",
    "    sum_score = sum_score/(len(test_predict)-1)\n",
    "\n",
    "    print sum_score\n",
    "\n",
    "    '''\n",
    "    rmse_val = sess.run(rmse, feed_dict={\n",
    "                    targets: testY, predictions: test_predict})\n",
    "\n",
    "    print(\"RMSE: {}\".format(rmse_val))\n",
    "\n",
    "    # Successful Rate\n",
    "    sum_score = 0.0;\n",
    "\n",
    "    for i in range(test_size-1):\n",
    "        sum_score = sum_score + sum((testY[i] < testY[i+1]) == (test_predict[i] < test_predict[i+1]))\n",
    "    \n",
    "    print \"Successful Rate: \", sum_score/(test_size-1)\n",
    "    '''\n",
    "\n",
    "    # Plot predictions\n",
    "    plt.plot(testY)\n",
    "    plt.plot(test_predict)\n",
    "    plt.xlabel(\"Time Period\")\n",
    "    plt.ylabel(\"Stock Price\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
